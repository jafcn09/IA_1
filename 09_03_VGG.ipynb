{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jafcn09/IA_1/blob/main/09_03_VGG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG\n",
        "\n",
        "https://www.kaggle.com/code/blurredmachine/vggnet-16-architecture-a-complete-guide/notebook"
      ],
      "metadata": {
        "id": "u6oIrx0nCWbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "5VWNoznzCVC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_input = Input((224,224,1)) # input shape\n"
      ],
      "metadata": {
        "id": "9ZuFldSVCovA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# modelo"
      ],
      "metadata": {
        "id": "qMEhmCX3C0RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\n",
        "conv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\n",
        "pool1  = MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "conv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\n",
        "conv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\n",
        "pool2  = MaxPooling2D((2, 2))(conv4)\n",
        "\n",
        "conv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\n",
        "conv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\n",
        "conv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\n",
        "pool3  = MaxPooling2D((2, 2))(conv7)\n",
        "\n",
        "conv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\n",
        "conv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\n",
        "conv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\n",
        "pool4  = MaxPooling2D((2, 2))(conv10)\n",
        "\n",
        "conv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\n",
        "conv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\n",
        "conv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\n",
        "pool5  = MaxPooling2D((2, 2))(conv13)\n",
        "\n",
        "flat   = Flatten()(pool5)\n",
        "dense1 = Dense(4096, activation=\"relu\")(flat)\n",
        "dense2 = Dense(4096, activation=\"relu\")(dense1)\n",
        "output = Dense(1000, activation=\"softmax\")(dense2)\n",
        "\n",
        "vgg16_model  = Model(inputs=_input, outputs=output)"
      ],
      "metadata": {
        "id": "TjHSl5E1Cqb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# usando modelos pre-entrenados"
      ],
      "metadata": {
        "id": "Vz2qnJHbC22a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "img1 = \"../input/flowers-recognition/flowers/tulip/10094729603_eeca3f2cb6.jpg\"\n",
        "img2 = \"../input/flowers-recognition/flowers/dandelion/10477378514_9ffbcec4cf_m.jpg\"\n",
        "img3 = \"../input/flowers-recognition/flowers/sunflower/10386540696_0a95ee53a8_n.jpg\"\n",
        "img4 = \"../input/flowers-recognition/flowers/rose/10090824183_d02c613f10_m.jpg\"\n",
        "imgs = [img1, img2, img3, img4]\n",
        "\n",
        "def _load_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "def _get_predictions(_model):\n",
        "    f, ax = plt.subplots(1, 4)\n",
        "    f.set_size_inches(80, 40)\n",
        "    for i in range(4):\n",
        "        ax[i].imshow(Image.open(imgs[i]).resize((200, 200), Image.ANTIALIAS))\n",
        "    plt.show()\n",
        "\n",
        "    f, axes = plt.subplots(1, 4)\n",
        "    f.set_size_inches(80, 20)\n",
        "    for i,img_path in enumerate(imgs):\n",
        "        img = _load_image(img_path)\n",
        "        preds  = decode_predictions(_model.predict(img), top=3)[0]\n",
        "        b = sns.barplot(y=[c[1] for c in preds], x=[c[2] for c in preds], color=\"gray\", ax=axes[i])\n",
        "        b.tick_params(labelsize=55)\n",
        "        f.tight_layout()"
      ],
      "metadata": {
        "id": "iTJWoq_sC4_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "vgg16_weights = '../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "vgg16_model = VGG16(weights=vgg16_weights)\n",
        "_get_predictions(vgg16_model)"
      ],
      "metadata": {
        "id": "jBLYhslBC8Lk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}